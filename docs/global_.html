<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>sortedness.global_ API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>sortedness.global_</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#  Copyright (c) 2023. Davi Pereira dos Santos
#  This file is part of the sortedness project.
#  Please respect the license - more about this in the section (*) below.
#
#  sortedness is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  sortedness is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with sortedness.  If not, see &lt;http://www.gnu.org/licenses/&gt;.
#
#  (*) Removing authorship by any means, e.g. by distribution of derived
#  works or verbatim, obfuscated, compiled or rewritten versions of any
#  part of this work is illegal and it is unethical regarding the effort and
#  time spent here.
#

import numpy as np
import pathos.multiprocessing as mp
from numpy import eye, ndarray
from numpy.random import permutation
from scipy.spatial.distance import pdist
from scipy.stats import kendalltau


def global_pwsortedness(X, X_, parallel=True, parallel_n_trigger=10000, **parallel_kwargs):
    &#34;&#34;&#34;
    Global pairwise sortedness (Œõùúè1)

    # TODO?: add flag to break extremely rare cases of ties that persist after projection (implies a much slower algorithm)
        This probably doesn&#39;t make any difference on the result, except on categorical, pathological or toy datasets
        Values can be lower due to the presence of ties, but only when the projection isn&#39;t prefect for all points.
        In the end, it might be even desired to penalize ties, as they don&#39;t exactly contribute to a stronger ordering and are (probabilistically) easier to be kept than a specific order.

    Parameters
    ----------
    X
        Original dataset or precalculated pairwise squared distances from pdist(X, metric=&#34;sqeuclidean&#34;)
    X_
        Projected points or precalculated pairwise squared distances from pdist(X, metric=&#34;sqeuclidean&#34;)
    parallel
        None: Avoid high-memory parallelization
        True: Full parallelism
        False: No parallelism
    parallel_kwargs
        Any extra argument to be provided to pathos parallelization
    parallel_n_trigger
        Threshold to disable parallelization for small n values

    Returns
    -------
    (Œõùúè1, p-value)
        The p-value considers the absence of order (Œõùúè1 = 0) as the null hypothesis.

    &gt;&gt;&gt; ll = [[i] for i in range(17)]
    &gt;&gt;&gt; a, b = np.array(ll), np.array(ll[0:1] + list(reversed(ll[1:])))
    &gt;&gt;&gt; b.ravel()
    array([ 0, 16, 15, 14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1])
    &gt;&gt;&gt; global_pwsortedness(a, b)
    SignificanceResult(statistic=0.76, pvalue=1.6669837696943839e-34)
    &gt;&gt;&gt; rnd = np.random.default_rng(0)
    &gt;&gt;&gt; rnd.shuffle(ll)
    &gt;&gt;&gt; b = np.array(ll)
    &gt;&gt;&gt; b.ravel()
    array([ 2, 10,  3, 11,  0,  4,  7,  5, 16, 12, 13,  6,  9, 14,  8,  1, 15])
    &gt;&gt;&gt; global_pwsortedness(a, b)
    SignificanceResult(statistic=0.04141176470588235, pvalue=0.5044358739518093)
    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; from functools import partial
    &gt;&gt;&gt; from scipy.stats import spearmanr, weightedtau
    &gt;&gt;&gt; mean = (1, 2)
    &gt;&gt;&gt; cov = eye(2)
    &gt;&gt;&gt; rng = np.random.default_rng(seed=0)
    &gt;&gt;&gt; original = rng.multivariate_normal(mean, cov, size=12)
    &gt;&gt;&gt; from sklearn.decomposition import PCA
    &gt;&gt;&gt; projected2 = PCA(n_components=2).fit_transform(original)
    &gt;&gt;&gt; projected1 = PCA(n_components=1).fit_transform(original)
    &gt;&gt;&gt; np.random.seed(0)
    &gt;&gt;&gt; projectedrnd = permutation(original)
    &gt;&gt;&gt; global_pwsortedness(original, original, f=kendalltau, return_pvalues=True)
    SignificanceResult(statistic=1.0, pvalue=3.6741408919675163e-93)
    &gt;&gt;&gt; global_pwsortedness(original, projected2, f=kendalltau)
    SignificanceResult(statistic=1.0, pvalue=3.6741408919675163e-93)
    &gt;&gt;&gt; global_pwsortedness(original, projected1, f=kendalltau)
    SignificanceResult(statistic=0.7715617715617715, pvalue=5.240847664048334e-20)
    &gt;&gt;&gt; global_pwsortedness(original, projectedrnd, f=kendalltau)
    SignificanceResult(statistic=-0.06107226107226107, pvalue=0.46847188611226276)
    &#34;&#34;&#34;
    # TODO: parallelize pdist into a for?
    thread = lambda M: pdist(M, metric=&#34;sqeuclidean&#34;)
    npoints = len(X)
    tmap = mp.ThreadingPool(**parallel_kwargs).imap if parallel and npoints &gt; parallel_n_trigger else map
    dists_X, dists_X_ = tmap(thread, [X, X_])
    return kendalltau(dists_X, dists_X_)


def cov2dissimilarity(M: ndarray):
    &#34;&#34;&#34;

    Parameters
    ----------
    M

    Returns
    -------

    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; cov2dissimilarity(np.array([[1,2],[3,4]]))
    array([[ 0.,  1.],
           [-1.,  0.]])
    &#34;&#34;&#34;
    variances = M.diagonal()
    dissimilarities = np.zeros(M.shape)
    for i in range(M.shape[0]):
        for j in range(M.shape[1]):
            dissimilarities[i, j] = variances[i] + variances[j] - 2 * M[i, j]
    return dissimilarities</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="sortedness.global_.cov2dissimilarity"><code class="name flex">
<span>def <span class="ident">cov2dissimilarity</span></span>(<span>M:¬†numpy.ndarray)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>M</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; cov2dissimilarity(np.array([[1,2],[3,4]]))
&lt;code&gt;array(\[\[ 0.,  1.],&lt;/code&gt;
:   [-1.,  0.]])


</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cov2dissimilarity(M: ndarray):
    &#34;&#34;&#34;

    Parameters
    ----------
    M

    Returns
    -------

    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; cov2dissimilarity(np.array([[1,2],[3,4]]))
    array([[ 0.,  1.],
           [-1.,  0.]])
    &#34;&#34;&#34;
    variances = M.diagonal()
    dissimilarities = np.zeros(M.shape)
    for i in range(M.shape[0]):
        for j in range(M.shape[1]):
            dissimilarities[i, j] = variances[i] + variances[j] - 2 * M[i, j]
    return dissimilarities</code></pre>
</details>
</dd>
<dt id="sortedness.global_.global_pwsortedness"><code class="name flex">
<span>def <span class="ident">global_pwsortedness</span></span>(<span>X, X_, parallel=True, parallel_n_trigger=10000, **parallel_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Global pairwise sortedness (Œõùúè1)</p>
<h1 id="todo-add-flag-to-break-extremely-rare-cases-of-ties-that-persist-after-projection-implies-a-much-slower-algorithm">TODO?: add flag to break extremely rare cases of ties that persist after projection (implies a much slower algorithm)</h1>
<pre><code>This probably doesn't make any difference on the result, except on categorical, pathological or toy datasets
Values can be lower due to the presence of ties, but only when the projection isn't prefect for all points.
In the end, it might be even desired to penalize ties, as they don't exactly contribute to a stronger ordering and are (probabilistically) easier to be kept than a specific order.
</code></pre>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>X</code></strong></dt>
<dd>Original dataset or precalculated pairwise squared distances from pdist(X, metric="sqeuclidean")</dd>
<dt><strong><code>X_</code></strong></dt>
<dd>Projected points or precalculated pairwise squared distances from pdist(X, metric="sqeuclidean")</dd>
<dt><strong><code>parallel</code></strong></dt>
<dd>None: Avoid high-memory parallelization
True: Full parallelism
False: No parallelism</dd>
<dt><strong><code>parallel_kwargs</code></strong></dt>
<dd>Any extra argument to be provided to pathos parallelization</dd>
<dt><strong><code>parallel_n_trigger</code></strong></dt>
<dd>Threshold to disable parallelization for small n values</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>(Œõùúè1, p-value)
The p-value considers the absence of order (Œõùúè1 = 0) as the null hypothesis.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; ll = [[i] for i in range(17)]
&gt;&gt;&gt; a, b = np.array(ll), np.array(ll[0:1] + list(reversed(ll[1:])))
&gt;&gt;&gt; b.ravel()
&lt;code&gt;array(\[ 0, 16, 15, 14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1])&lt;/code&gt;
:   &amp;nbsp;


&gt;&gt;&gt; global_pwsortedness(a, b)
`SignificanceResult(statistic=0.76, pvalue=1.6669837696943839e-34)`
:   &amp;nbsp;


&gt;&gt;&gt; rnd = np.random.default_rng(0)
&gt;&gt;&gt; rnd.shuffle(ll)
&gt;&gt;&gt; b = np.array(ll)
&gt;&gt;&gt; b.ravel()
&lt;code&gt;array(\[ 2, 10,  3, 11,  0,  4,  7,  5, 16, 12, 13,  6,  9, 14,  8,  1, 15])&lt;/code&gt;
:   &amp;nbsp;


&gt;&gt;&gt; global_pwsortedness(a, b)
`SignificanceResult(statistic=0.04141176470588235, pvalue=0.5044358739518093)`
:   &amp;nbsp;


&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from functools import partial
&gt;&gt;&gt; from scipy.stats import spearmanr, weightedtau
&gt;&gt;&gt; mean = (1, 2)
&gt;&gt;&gt; cov = eye(2)
&gt;&gt;&gt; rng = np.random.default_rng(seed=0)
&gt;&gt;&gt; original = rng.multivariate_normal(mean, cov, size=12)
&gt;&gt;&gt; from sklearn.decomposition import PCA
&gt;&gt;&gt; projected2 = PCA(n_components=2).fit_transform(original)
&gt;&gt;&gt; projected1 = PCA(n_components=1).fit_transform(original)
&gt;&gt;&gt; np.random.seed(0)
&gt;&gt;&gt; projectedrnd = permutation(original)
&gt;&gt;&gt; global_pwsortedness(original, original, f=kendalltau, return_pvalues=True)
`SignificanceResult(statistic=1.0, pvalue=3.6741408919675163e-93)`
:   &amp;nbsp;


&gt;&gt;&gt; global_pwsortedness(original, projected2, f=kendalltau)
`SignificanceResult(statistic=1.0, pvalue=3.6741408919675163e-93)`
:   &amp;nbsp;


&gt;&gt;&gt; global_pwsortedness(original, projected1, f=kendalltau)
`SignificanceResult(statistic=0.7715617715617715, pvalue=5.240847664048334e-20)`
:   &amp;nbsp;


&gt;&gt;&gt; global_pwsortedness(original, projectedrnd, f=kendalltau)
`SignificanceResult(statistic=-0.06107226107226107, pvalue=0.46847188611226276)`
:   &amp;nbsp;


</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def global_pwsortedness(X, X_, parallel=True, parallel_n_trigger=10000, **parallel_kwargs):
    &#34;&#34;&#34;
    Global pairwise sortedness (Œõùúè1)

    # TODO?: add flag to break extremely rare cases of ties that persist after projection (implies a much slower algorithm)
        This probably doesn&#39;t make any difference on the result, except on categorical, pathological or toy datasets
        Values can be lower due to the presence of ties, but only when the projection isn&#39;t prefect for all points.
        In the end, it might be even desired to penalize ties, as they don&#39;t exactly contribute to a stronger ordering and are (probabilistically) easier to be kept than a specific order.

    Parameters
    ----------
    X
        Original dataset or precalculated pairwise squared distances from pdist(X, metric=&#34;sqeuclidean&#34;)
    X_
        Projected points or precalculated pairwise squared distances from pdist(X, metric=&#34;sqeuclidean&#34;)
    parallel
        None: Avoid high-memory parallelization
        True: Full parallelism
        False: No parallelism
    parallel_kwargs
        Any extra argument to be provided to pathos parallelization
    parallel_n_trigger
        Threshold to disable parallelization for small n values

    Returns
    -------
    (Œõùúè1, p-value)
        The p-value considers the absence of order (Œõùúè1 = 0) as the null hypothesis.

    &gt;&gt;&gt; ll = [[i] for i in range(17)]
    &gt;&gt;&gt; a, b = np.array(ll), np.array(ll[0:1] + list(reversed(ll[1:])))
    &gt;&gt;&gt; b.ravel()
    array([ 0, 16, 15, 14, 13, 12, 11, 10,  9,  8,  7,  6,  5,  4,  3,  2,  1])
    &gt;&gt;&gt; global_pwsortedness(a, b)
    SignificanceResult(statistic=0.76, pvalue=1.6669837696943839e-34)
    &gt;&gt;&gt; rnd = np.random.default_rng(0)
    &gt;&gt;&gt; rnd.shuffle(ll)
    &gt;&gt;&gt; b = np.array(ll)
    &gt;&gt;&gt; b.ravel()
    array([ 2, 10,  3, 11,  0,  4,  7,  5, 16, 12, 13,  6,  9, 14,  8,  1, 15])
    &gt;&gt;&gt; global_pwsortedness(a, b)
    SignificanceResult(statistic=0.04141176470588235, pvalue=0.5044358739518093)
    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; from functools import partial
    &gt;&gt;&gt; from scipy.stats import spearmanr, weightedtau
    &gt;&gt;&gt; mean = (1, 2)
    &gt;&gt;&gt; cov = eye(2)
    &gt;&gt;&gt; rng = np.random.default_rng(seed=0)
    &gt;&gt;&gt; original = rng.multivariate_normal(mean, cov, size=12)
    &gt;&gt;&gt; from sklearn.decomposition import PCA
    &gt;&gt;&gt; projected2 = PCA(n_components=2).fit_transform(original)
    &gt;&gt;&gt; projected1 = PCA(n_components=1).fit_transform(original)
    &gt;&gt;&gt; np.random.seed(0)
    &gt;&gt;&gt; projectedrnd = permutation(original)
    &gt;&gt;&gt; global_pwsortedness(original, original, f=kendalltau, return_pvalues=True)
    SignificanceResult(statistic=1.0, pvalue=3.6741408919675163e-93)
    &gt;&gt;&gt; global_pwsortedness(original, projected2, f=kendalltau)
    SignificanceResult(statistic=1.0, pvalue=3.6741408919675163e-93)
    &gt;&gt;&gt; global_pwsortedness(original, projected1, f=kendalltau)
    SignificanceResult(statistic=0.7715617715617715, pvalue=5.240847664048334e-20)
    &gt;&gt;&gt; global_pwsortedness(original, projectedrnd, f=kendalltau)
    SignificanceResult(statistic=-0.06107226107226107, pvalue=0.46847188611226276)
    &#34;&#34;&#34;
    # TODO: parallelize pdist into a for?
    thread = lambda M: pdist(M, metric=&#34;sqeuclidean&#34;)
    npoints = len(X)
    tmap = mp.ThreadingPool(**parallel_kwargs).imap if parallel and npoints &gt; parallel_n_trigger else map
    dists_X, dists_X_ = tmap(thread, [X, X_])
    return kendalltau(dists_X, dists_X_)</code></pre>
</details>
</dd>
<dt id="sortedness.global_.permutation"><code class="name flex">
<span>def <span class="ident">permutation</span></span>(<span>x)</span>
</code></dt>
<dd>
<div class="desc"><p>Randomly permute a sequence, or return a permuted range.</p>
<p>If <code>x</code> is a multi-dimensional array, it is only shuffled along its
first index.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>New code should use the
<code>~numpy.random.Generator.permutation</code>
method of a <code>~numpy.random.Generator</code> instance instead;
please see the :ref:<code>random-quick-start</code>.</p>
</div>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>int</code> or <code>array_like</code></dt>
<dd>If <code>x</code> is an integer, randomly permute <code>np.arange(x)</code>.
If <code>x</code> is an array, make a copy and shuffle the elements
randomly.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>out</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>Permuted sequence or array range.</dd>
</dl>
<h2 id="see-also">See Also</h2>
<dl>
<dt><code>random.Generator.permutation</code></dt>
<dd>which should be used for new code.</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; np.random.permutation(10)
array([1, 7, 4, 3, 0, 9, 2, 5, 8, 6]) # random
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; np.random.permutation([1, 4, 9, 12, 15])
array([15,  1,  9,  4, 12]) # random
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; arr = np.arange(9).reshape((3, 3))
&gt;&gt;&gt; np.random.permutation(arr)
array([[6, 7, 8], # random
       [0, 1, 2],
       [3, 4, 5]])
</code></pre></div>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="sortedness" href="index.html">sortedness</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="sortedness.global_.cov2dissimilarity" href="#sortedness.global_.cov2dissimilarity">cov2dissimilarity</a></code></li>
<li><code><a title="sortedness.global_.global_pwsortedness" href="#sortedness.global_.global_pwsortedness">global_pwsortedness</a></code></li>
<li><code><a title="sortedness.global_.permutation" href="#sortedness.global_.permutation">permutation</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>